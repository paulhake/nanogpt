# nanoGPT

This repository is based on the nanoGPT lecture series by Andrej Karpathy.

## About

Implementation of a simple bigram language model following Karpathy's educational tutorials on building GPT from scratch. The code demonstrates fundamental concepts of transformer-based language models using PyTorch.

## Files

- `bigram.py` - Simple bigram language model implementation
- `gpt-dev.ipynb` - Development notebook for experimentation
- `input.txt` - Training data (Shakespeare text)
- `requirements.txt` - Python dependencies

## Usage

```bash
pip install -r requirements.txt
python bigram.py
```

## Source

Based on Andrej Karpathy's nanoGPT lecture series and educational materials.